%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Evaluation Techniques}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{abstract}
Text summarization is a challenging task.  Maintaining linguistic quality, optimizing both compression and retention, all while avoiding redundancy and preserving the substance of a text is a difficult process.  Equally difficult is the task of evaluating such summaries.  Interestingly, a summary generated from the same document can be different when written by different humans (or by the same human at different times).  Hence, there is no convenient, complete set of rules to test a machine generated summary. In this paper, we propose a methodology for evaluating extractive summaries.  We argue that the overlap between two summaries should be compared against the \emph{average intersection size} of two random generated \emph{baselines} and propose ranking machine generated summaries based on the concept of \emph{closeness} with respect to reference summaries. The key idea of our methodology is the use of \emph{weighted relatedness} towards the reference summaries, normalized by the relatedness of reference summaries among themselves. Our approach suggests a relative scale, and is tolerant towards the length of the summary. 
%\keywords{evaluation technique, baseline, summarization, random average, reference summary, machine-generated summary}
%\end{abstract}



\section{Type \texorpdfstring{$B_n$}{Bn}: Odd dimensional, orthogonal Lie
  algebras} 

The odd dimensional, orthogonal Lie algebra $\fso_{2n+1}(\BBC)$, or simply
$\fso_{2n+1}$, is the set of all matrices $X$ in $\fgl_{2n}(\BBC)$ such that
\[
JX= -X^t J
\]
where $J= \left[\begin{smallmatrix} 1&0&0\\ 0 &0&I_n\\ 0&I_n
    &0\end{smallmatrix} \right]$.  Suppose $X=\left[\begin{smallmatrix}
    a&s&t\\ u&A&B\\ v&C& D \end{smallmatrix} \right]$ where $a$ is a complex
number, $s,t,u,v$ are vectors with $n$ components, and $A, B, C, D$ are
$n\times n$ matrices. Then $JX= -X^t J$ if and only if
\[
\begin{bmatrix}
  1&0&0\\ 0&0&I_n\\ 0&I_n& 0
\end{bmatrix}
\begin{bmatrix}
  a&s&t\\ u&A&B\\ v&C& D
\end{bmatrix}
=
\begin{bmatrix}
  -a&-u^t&-v^t\\-s^t&-A^t&-C^t\\ -t^t&-B^t&-D^t
\end{bmatrix}
\begin{bmatrix}
  1&0&0\\ 0&0&I_n\\ 0&I_n& 0
\end{bmatrix},
\]
which is if and only if
\[
a=0\quad u=-t^t \quad v=-s^t\quad D=-A^t,\quad B=-B^t,\quad\text{and} \quad
C=-C^t.
\]
If the $i\th$ entry of $s$ is $s_i$, $i\th$ entry of $t$ is $t_i$, the
$(i,j)$ entry of $A$ is $a_{i,j}$, the $(i,j)$ entry of $B$ is $b_{i,j}$,
and the $(i,j)$ entry of $C$ is $c_{i,j}$, then $\left[\begin{smallmatrix}
    a&s&t\\ u&A&B\\ v&C& D \end{smallmatrix} \right]$ is in $\fso_{2n+1}$ if
and only if
\[
\begin{bmatrix}
  a&s&t\\ u&A&B\\ v&C& D
\end{bmatrix}
=
\begin{bmatrix}
  0&s_1&s_2&\dots&s_n &t_1&t_2&\dots&t_n\\
  -t_1& a_{1,1}&a_{1,2}&\dots&a_{1,n}&0&b_{1,2}&\dots&b_{1,n} \\
  -t_2& a_{2,1}&a_{2,2}&\dots&a_{2,n}&-b_{2,1}&0&\dots&b_{2,n} \\
  \vdots&\vdots&\vdots&\ddots&\vdots&\vdots&\vdots&\ddots&\vdots \\
  -t_n& a_{n,1}&a_{n,2}&\dots&a_{n,n}&-b_{n,1}&-b_{n,2}&\dots&0 \\
  -s_1& 0&c_{1,2}&\dots&c_{1,n}&-a_{1,1}&-a_{n,2}&\dots&-a_{n,1} \\
  -s_2& -c_{2,1}&0&\dots&c_{1,n}&-a_{2,1}&-a_{2,2}&\dots&-a_{2,n} \\
  \vdots & \vdots&\vdots&\ddots&\vdots&\vdots&\vdots&\ddots&\vdots \\
  -s_n& -c_{n,1}&-c_{n,2}&\dots&0&-a_{1,n}&-a_{n,2}&\dots&-a_{n,n}
\end{bmatrix}.
\]

For $1\leq i\leq n$ define
\[
d_i= e_{i+1,i+1}-e_{n+i+1,n+i+1}.
\]
Then
\[
\CB_H= \{\,d_i\mid 1\leq i\leq n\,\}= \{\,e_{i+1,i+1}-e_{n+i+1,n+i+1}\mid
1\leq i\leq n\,\}.
\]
is a basis of $H$.

For $1\leq i\leq n$, define $x_i$ in $H^*$ by
\[
x_i(h)= a_i\quad\text{when}\quad h=\diag{0,\seq a, \seq{-a}}.
\]
Then $x_i(h)$ is the coefficient of $d_i$ when $h$ is expressed as a linear
combination of vectors in $\CB_H$.

The set
\begin{multline*}
  \CB=\CB_H \cup \{\, e_{1, j+1}-e_{n+j+1,1}\mid 1\leq j\leq n\,\} \cup \{\,
  e_{1, n+j+1}-e_{j+1,1}\mid 1\leq j\leq n\,\} \\
  \cup \{\, e_{i+1,j+1} -e_{n+j+1, n+i+1} \mid 1\leq i\ne j\leq n\,\} \cup
  \{\, e_{i+1,n+j+1} -e_{j+1, n+i+1} \mid 1\leq i< j\leq n\,\}  \\
  \cup \{\, e_{n+i+1,j+1} -e_{n+j+1, i+1}\mid 1\leq i< j\leq n\,\}
\end{multline*}
is a basis of $\fso_{2n+1}$. In particular, $\dim \fso_{2n+1}=
3n+n^2-n+2\binom n2= 2n^2+n$.

\begin{proposition}
  The set $\CB\setminus \CB_H$ consists of root vectors.
\end{proposition}

\begin{proof}
  This is proved by direct computation. There are five cases.

  Suppose that $h=\diag{0,\seq a, \seq{-a}}$ is in $H$.

  Consider $e_{1, j+1}-e_{n+j+1,1}$ where $1\leq j\leq n$. Then
  \begin{align*}
    [h, e_{1, j+1}-e_{n+j+1,1}]& =[h,e_{1,j+1}] -[h,e_{n+j+1, 1}]\\
    &= -a_j\, e_{1,j+1} -a_{j} \, e_{n+j+1, 1} \\
    &= (-a_j)\, (e_{1, j+1}-e_{n+j+1,1}) \\
    &= (-x_j)(h) \, (e_{1, j+1}-e_{n+j+1,1}).
  \end{align*}
  Thus, $e_{1, j+1}-e_{n+j+1,1}$ is a root vector. The corresponding root is
  the linear function $-x_j$ in $H^*$.

  Consider $e_{i+1,j+1} -e_{n+j+1, n+i+1}$ where $1\leq i\ne j\leq n$. Then
  \begin{align*}
    [h, e_{i+1,j+1} -e_{n+j+1, n+i+1}]& =[h,e_{i+1,j+1}] -[h,e_{n+j+1,
      n+i+1}]\\
    &= (a_i-a_j)\, e_{i+1,j+1} - (-a_{j} + a_{i}) \, e_{n+j+1, n+i+1} \\
    &= (a_i-a_j)\, (e_{i+1,j+1} -e_{n+j+1, n+i+1}) \\
    &= (x_i-x_j)(h) \, (e_{i+1,j+1} -e_{n+j+1, n+i+1}).
  \end{align*}
  Thus, $e_{i+1,j+1} -e_{n+j+1, n+i+1}$ is a root vector. The corresponding
  root is the linear function $x_i-x_j$ in $H^*$.

  Consider $e_{i+1,n+j+1} -e_{j+1, n+i+1}$ where $1\leq i<j\leq n$. Then
  \begin{align*}
    [h, e_{i+1,n+j+1} -e_{j+1, n+i+1}]& =[h,e_{i+1,n+j+1} ] -[h,e_{j+1,
      n+i+1}]\\
    &= (a_i+a_j)\, e_{i+1,n+j+1} - (a_{j} + a_{i}) \, e_{j+1, n+i+1} \\
    &= (a_i+a_j)\, (e_{i+1,n+j+1} -e_{j+1, n+i+1}) \\
    &= (x_i+x_j)(h) \,e_{i+1,n+j+1} -e_{j+1, n+i+1}.
  \end{align*}
  Thus, $e_{i+1,n+j+1} -e_{j+1, n+i+1}$ is a root vector. The corresponding
  root is the linear function $x_i+x_j$ in $H^*$.

  The other two cases are similar: $e_{1,n+j+1} -e_{j+1, 1}$ is a root
  vector and the corresponding root is the linear function $x_j$ in $H^*$;
  $e_{n+i+1,j+1} -e_{j+1, n+i+1}$ is a root vector and the corresponding
  root is the linear function $-x_i-x_j$ in $H^*$.

  The computations above are summarized in Table~\ref{tab:soodd}.
  \begin{table}[h!tb]
    \small \arraycolsep10pt
    \renewcommand{\arraystretch}{1.3}
    \begin{equation*}
      \begin{array}{l|cc}
        i,\ j &\alpha &e_\alpha\\\hline
        1\leq j\leq n&-x_j & e_{1,j+1} -e_{n+j+1, 1}\\
        1\leq j\leq n&x_j & e_{1,n+j+1} -e_{j+1, 1}\\
        1\leq i\ne j\leq n&x_i-x_j &  e_{i+1,j+1} -e_{n+j+1, n+i+1} \\
        1\leq i< j\leq n&x_i+x_j & e_{i+1,n+j+1} -e_{j+1, n+i+1} \\ 
        1\leq i< j\leq n&-x_i-x_j & e_{n+i+1,j+1} -e_{j+1, n+i+1}
      \end{array}  
    \end{equation*}
    \caption{Roots and root vectors for $\fso_{2n+1}(\BBC)$}\label{tab:soodd}
  \end{table}
\end{proof}

\begin{corollary}
  The the subalgebra $H$ is a maximal toral subalgebra and the root system
  of $(\fso_{2n+1}, H)$ is
  \[
  \Phi=\{\pm(x_i\pm x_j) \mid 1\leq i<j\leq n\,\} \cup \{\, 2x_i\mid 1\leq
  i\leq n\,\}.
  \]
\end{corollary}

\begin{proof}
  By the proposition, $\fso_{2n+1}$ has a root space decomposition. Suppose
  that $H'$ is a toral subalgebra containing $H$. Just suppose that $H'$
  properly contains $H$. Then $H'$ is abelian and there is an element $h'$
  in $H$ that is a linear combination of the basis elements in $\CB\setminus
  \CB_H$. Write $h'=v_\alpha+h''$ where $v_\alpha$ is a non-zero vector in
  the $\alpha$ root space. Then $v_\alpha$ is a non-zero multiple of the
  root vector $e_\alpha$ in $\CB\setminus \CB_H$. Fix $h$ in $H$ such that
  $h$ is not in $\ker \alpha$, then $[h,h']= [h, v_\alpha+h'']=
  \alpha(h)v_\alpha + [h,h'']$. Then $\alpha(h)v_\alpha\ne 0$ and $[h, h'']$
  is in the span of $\CB\setminus(\CB_H\cup \{e_\alpha\})$. Therefore,
  $[h,h'] \ne0$. This contradicts the fact that $H'$ is abelian. Thus,
  $H'=H$ and so $H$ is maximal.
\end{proof}

For $1\leq i\leq n$ define $\alpha_i$ in $H^*$ by
\begin{align*}
  \alpha_i&=x_i-x_{i+1} \quad (1\leq i\leq n-1),\\
  \alpha_n&= x_n.
\end{align*}
Set $\Pi=\{\, \alpha_i\mid 1\leq i\leq n\,\}$. It's easy to see that $\Pi$
is a basis of $H^*$. In Table~\ref{tab:sodplus} each root in $\Phi$ is given
as a linear combination of roots in $\Pi$. Notice that the roots $x_i-x_j$
with $i\ne j$ from Table~\ref{tab:soodd} are split into two subsets depending
on whether or not $i<j$.

\begin{table}[h!tb]
  \footnotesize \arraycolsep10pt
  \renewcommand{\arraystretch}{1.3}
  \begin{equation*}
    \begin{array}{l|rclc}
      i,\ j &\alpha&=&\sum_{i=1}^n m_i\alpha_i&\height(\alpha)\\\hline
      1\leq i< j\leq n&  x_i-x_j& =& \alpha_{i}+ \dots +\alpha_{j-1}& j-i \\
      1\leq i\leq n& x_i&=& \alpha_i+\dots +\alpha_{n-1}+ \alpha_n &
      n-i+1\\ 
      1\leq i< j\leq n& x_i+x_j&=& \alpha_i+ \dots +\alpha_{j-1} + 2\alpha_j+
      \dots +2\alpha_{n-1} +2\alpha_n& 2n-i-j+2 \\ 
      1\leq i< j\leq n& - x_i+x_j& =& -\alpha_{i}- \dots -\alpha_{j-1}& -j+i \\
      1\leq i\leq n& -x_i &= &-\alpha_i-\dots -\alpha_{n-1}- \alpha_n &
      -n+i-1\\ 
      1\leq i< j\leq n&  -x_i-x_j&=& -\alpha_i- \dots -\alpha_{j-1} - 2\alpha_j-
      \dots -2\alpha_{n-1} -2\alpha_n& -2n+i+j-2   
    \end{array}  
  \end{equation*}
  \caption{Roots expressed as linear combinations of vectors in
    $\Pi$}\label{tab:sodplus} 
\end{table}

By direct inspection, there is a unique root with maximal height, this is
the \emph{highest root}. The highest root is
$x_1+x_2=\alpha_1+2\alpha_2+\dots + 2\alpha_n$ and its height is $2n-1$.

The usual Euclidean metric on $H^*$ is defined by 
\[
d(\sum_{i=1}^n a_i x_i, \sum_{i=1}^n b_i x_i) = \sqrt{ \sum_{i=1}^n
  |a_i-b_i|^2}.
\]
With respect to this metric, the roots $\pm (x_i\pm x_j)$ with $i\ne j$ have
length $\sqrt 2$ and the roots $\pm x_i$ have length $1$. Thus, there are
two root lengths. Roots with minimum length are called \emph{short roots}
and roots with maximum length are called \emph{long roots.} The highest root
is a long root.

By direct inspection, there is a unique highest short root,
$x_1=\alpha_1+\dots +\alpha_n$, with height $n$.

Notice that if $\alpha=\sum_{i=1}^n m_i\alpha_i$, then the coefficients
$m_i$ are either all non-negative or all non-positive. Define
\[
\Phi^+=\Big\{\, \alpha=\sum_{i=1}^n m_i\alpha_i\mid mi_\geq 0 \, \forall\,
1\leq i\leq n\,\Big\}
\]
and
\[
\Phi^- = \Big\{\, \alpha=\sum_{i=1}^n m_i\alpha_i\mid mi_\leq 0 \, \forall\,
1\leq i\leq n\,\Big\}.
\]
Then $\Phi^-= -\Phi^+$ and $\Phi = \Phi^+ \coprod \Phi^-$.

We next compute the elements $t_{\alpha_i}$ in $H$ for $1\leq i\leq
n$. Using the basis $\CB$ of $\fso_{2n+1}$ it is straightforward to compute
the restriction of the Killing form to $H$ by computing the matrices of $\ad
h$ and $\ad h'$, and then $\trace(\ad h\circ \ad h')$ for $h$ and $h'$ in
$H$. The result is
\[
\kappa(h,h')= \sum_{\alpha\in \Phi} \alpha(h) \alpha(h').
\]
If $h=\diag{0,\seq a, \seq{-a}}$ and $h'=\diag{0,\seq{a'}, \seq{-a'}}$, then
$\alpha(h) \alpha(h')$ is given in Table~\ref{tab:sodhh'}.

\begin{table}[h!tb]
  \small \arraycolsep10pt
  \renewcommand{\arraystretch}{1.3}
  \begin{equation*}
    \begin{array}{c|c}
      \alpha&\alpha(h) \alpha(h')\\\hline
      x_i-x_j& (a_i-a_j)(a_i'-a_j')\\
      x_i&(a_i)(a_i')= a_ia_i'\\ 
      x_i+x_j&(a_i+a_j)(a_i'+a_j')\\ 
      - x_i+x_j&(-a_i+a_j)(-a_i'+a_j')=(a_i-a_j)(a_i'-a_j')\\
      -x_i &(-a_i)(-a_i')=a_ia_i'\\ 
      -x_i-x_j&=(-a_i-a_j)(-a_i'-a_j')=(a_i+a_j)(a_i'+a_j') 
    \end{array}  
  \end{equation*}
  \caption{$\alpha(h) \alpha(h')$ when $h=\diag{\seq a}$ and
    $h'=\diag{\seq{a'}}$}\label{tab:sodhh'}  
\end{table}

We can now compute $\kappa(h,h')$ in terms of the coefficients of $h$ and
$h'$ when $h$ and $h'$ are expressed as linear combinations of $\{x_1,
\dots, x_n\}$. 

\begin{equation}
  \label{eq:sod1}
  \begin{aligned}
    \kappa(h,h')&= \sum_{1\leq i<j\leq n} 2\left( (a_i-a_j)(a_i'-a_j') +
      (a_i+a_j)(a_i'+a_j') \right) +2\sum_{i=1}^n \left( a_ia_i' \right)\\
    &= \sum_{1\leq i<j \leq n} (4a_ia_i' +4a_ja_j') +\sum_{i=1}^n 2a_ia_i'
    \\
    &= \sum_{i=1}^n a_ia_i' (2+4(n-i) +4(i-1))\\
    &=(4n-2) \sum_{i=1}^n a_ia_i'.
  \end{aligned}
\end{equation}
The penultimate equality in~(\ref{eq:sod1}) is most easily seen by arranging
the summands in an $n\times n$ array.
\[
%\small
\begin{array}{cccrrrrc}
  2a_1a_1'&4a_1a_1'+ 4a_2a_2'&4a_1a_1'+
  4a_3a_3'&&\dots&\dots&\dots&4a_{1}a_{1}'+ 4a_na_n' \\  
  &2a_2a_2'&4a_2a_2'+4a_3a_3'&&&&&4a_{2}a_{2}'+ 4a_na_n' \\
  &&2a_3a_3'&&&&&4a_{3}a_{3}'+ 4a_na_n' \\
  &&&&&&&\vdots\hphantom{+4a_na_n'}\\
  &&&&\ddots&&&\vdots\hphantom{+4a_na_n'}\\
  &&&&&&&4a_{n-2}a_{n-2}'+ 4a_na_n' \\ 
%  &&&&&&&4a_{n-1}a_{n-1}'+ 4a_na_n' \\
  &&&&&&&2a_na_n'
\end{array}
\]

For $1\leq i\leq n$. Then the element $t_{\alpha_i}$ in $H$ is defined by
the condition that
\[
\kappa(h, t_{\alpha_i}) = \alpha_i(h) \quad \text{for all $h$ in $H$.}
\]

Fix $1\leq i\leq n-1$ and suppose $t_{\alpha_i}= \diag{0,\seq t,
  \seq{-t}}$. Then
\begin{equation*}
  a_i-a_{i+1}= (4n-2)(a_1t_1+\dots+a_it_i+a_{i+1}t_{i+1}+ \dots +a_nt_n)
\end{equation*}
when $h=\diag{0,\seq a, \seq{-a}}$. Thus, $t_1$, \dots, $t_n$ are such that
\begin{equation*}
  \textstyle a_1t_1+\dots+a_i\big(t_i- \frac 1{4n-2} \big) +a_{i+1}
  \big(t_{i+1} +\frac 1{4n-2} \big)+  \dots +a_nt_n=0 
\end{equation*}
for all $a_1$, \dots, $a_n$ in $\BBC$. Taking $a_j=1$ and $a_k=0$ for $k\ne
j$ we see that
\[
t_j= \begin{cases} \textstyle \frac 1{4n-2}&j=i \\ -\frac 1{4n-2} &j=i+1 \\0
  &j\ne i, i+1. \end{cases}
\]
Therefore, for $1\leq i\leq n-1$, $t_{\alpha_i}=\frac 1{4n-2}( d_i-
d_{i+1})$.

Now consider $t_{\alpha_n}$. Say $t_{\alpha_i}= \diag{0,\seq t,
  \seq{-t}}$. Then
\begin{equation*}
  a_n= (4n-2)(a_1t_1+\dots+a_it_i+a_{i+1}t_{i+1}+ \dots +a_nt_n)
\end{equation*}
when $h=\diag{0,\seq a, \seq{-a}}$. Thus, $t_1$, \dots, $t_n$ are such that
\begin{equation*}
  \textstyle  a_1t_1+\dots+a_{n-1} t_{n-1} +a_n\big(t_n-\frac 1{4n-2}\big)=0 
\end{equation*}
for all $a_1$, \dots, $a_n$ in $\BBC$. Taking $a_j=1$ and $a_k=0$ for $k\ne
j$ we see that
\[
t_j= \begin{cases} \textstyle \frac 1{4n-2}&j=n \\ 0 &j\ne n. \end{cases}
\]
Therefore, $t_{\alpha_n}=\frac 1{4n-2} d_n$.

For $1\leq i\leq n-1$ we have
\[
\kappa(t_{\alpha_i}, t_{\alpha_i})= (4n-2) \left(\textstyle \frac
  1{(4n-2)^2} + \frac 1{(4n-2)^2}\right) = \frac 1{2n-1}.
\]
Also
\[
\kappa(t_{\alpha_n}, t_{\alpha_n})= (4n-2) \frac 1{(4n-2)^2} = \frac
1{4n-2}.
\]
Therefore
\begin{align*}
  h_{\alpha_i}&= (4n-2) t_{\alpha_i}= d_i-d_{i+1} \quad (1\leq i\leq n-1),\\
  h_{\alpha_n}&= (8n-4)t_{\alpha_n} = 2d_n.
\end{align*}

The \emph{Cartan matrix} of $\fso_{2n+1}$ (or of $\Phi$, when $t_{\alpha_i}$
is identified with $\check{\alpha_i}$) is the matrix $C(\fso_{2n+1})$ whose
$(i,j)$-entry is $\alpha_i(h_{\alpha_j})$. Using the computations above we
see that
\[
C(\fso_{2n+1})= 
\begin{bmatrix}
  2&-1&0&&&\dots&0 \\
  -1&2&-1&&&\dots&0 \\
  0&-1&2&&&\dots&0 \\  \vdots&&\ddots&\ddots&\ddots&&\vdots\\
  0&&\dots&&2&-1&0 \\
  0&&\dots&&-1&2&-2 \\
  0&&\dots&&0&-1&2
\end{bmatrix}.
\]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Type \texorpdfstring{$D_n$}{Dn}: Even dimensional, orthogonal Lie
  algebras} 




%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "mydissertation"
%%% End: 
